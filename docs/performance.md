# 識別性能の検証結果

## 概要

顔写真を8名に分類するタスクで分類モデルの精度と学習所要時間を検証した。  
短時間で学習できること、少数の学習データでも高い精度で分類できることが確認された。

## 目次

* [問題設定](#問題設定)
    - [データセット](#データセット)
    - [検証対象モデル](#検証対象モデル)
    - [検証内容](#検証内容)
    - [実行環境](#実行環境)
* [検証結果](#検証結果)
* [特徴量抽出器のCNN分類モデルとしての性能](#特徴量抽出器のCNN分類モデルとしての性能)

## 問題設定

顔写真から人を特定するタスク

### データセット

下記8名の写真を[Yahoo!画像検索で収集](./collect-imgs.md#yahoo画像検索を使う場合)し[顔の部分を切り出し](./create-dataset.md)て作成した、8クラス292枚の顔写真を用いる。データセットそのものは、肖像権と著作権の問題から公開しない。

```TSV
0	武井咲
1	中越典子
2	ケンドーコバヤシ
3	伊原剛志
4	小蜜
5	照英
6	壇蜜
7	木村祐一
```

また、分類対象とする8名の画像は特徴量抽出器の学習に使ったデータセットには含まれていない。

### 検証対象モデル

分類器はノード50個の中間層を持つ多層パーセプトロンとする。  
[学習済みの画像特徴量抽出器](docs/pre_trained_models.md)を切り替えて検証を行う。

### 検証内容

* 1
    - データセットを 訓練データ:評価データ = 7:3 の割合でランダムに振り分け、訓練データのみで学習させる。
    - 学習した識別モデルの、評価データに対する正答率を確認する。
    - 学習を50epoch実施するのにかかった時間を計測する。
* 2
    - 検証項目1の訓練データと評価データを逆転させて同様の検証を行い、訓練データが少ない場合の識別性能を確認する。

比較のため、v1のCNN再学習による精度と速度も掲載する。chainerのバージョンが変わったためv1モデルの精度も再計測したところ、[v1作成時の報告](docs/performance_v1.md#備考-転移学習に用いたデータに対する識別性能)よりも精度が向上した。chainer自体の改善によるものと思われるが、具体的な理由は不明。


### 実行環境

| 項目 | 値 |
| --- | --- |
| CPU | Ryzen 1700 |
| Memory | 16GB |
| Disk | M.2 SSD 256GB |
| OS | Ubuntu 16.04 |
| Cuda | 8.0 |
| Python | 3.5.2 |
| chainer | 3.0.0 |
| cupy | 2.0.0 |

CPUは8Core16Threadのモデルであるが、環境変数`OMP_NUM_THREADS=1`を設定して1Threadのみ使用した。

## 検証結果

### 検証1 訓練データが多い場合

| 特徴量抽出器 | 精度(%) | 学習時間(秒) |
| --- | --- | --- |
| V_12 | 90.0  | 18.0 |
| V_16 | 91.2 | 18.9 |
| V_20 | 95.0 | 19.9 |
| V2_16 | 95.0 | 23.4 |
| V2_20 | 90.0 | 26.2 |
| 備考: v1 A_16再学習 | 86.1 | 120.3 |
| 備考: v1 I2_24再学習 | 83.3 | 148.1 |

### 検証2 訓練データが少ない場合

| 特徴量抽出器 | 精度(%) | 学習時間(秒) |
| --- | --- | --- |
| V_12 | 77.2  | 8.5 |
| V_16 | 78.1 | 9.5 |
| V_20 | 81.8 | 10.8 |
| V2_16 | 82.7 | 13.4 |
| V2_20 | 81.8 | 17.1 |
| 備考: v1 A_16再学習 | 62.2 | 106.4 |
| 備考: v1 I2_24再学習 | 71.3 | 149.1 |

`V2_20`を除き、特徴量抽出器のCNNとしての精度が高いほど分類器の精度が高くなり、パラメータが増えることで処理時間は長くなった。`V2_20`はCNNとしては最も性能が高いが、特徴量抽出器としては有効でないことが分かった。  
v1と比べると精度・速度ともに大幅に改善している。

Raspberry Pi上での学習速度はまだ計測していない。v1時には1人あたり訓練画像9枚、評価画像なしで`A_16`を30epoch再学習するのに1人あたり50秒程度の所要時間だった。単純に比例計算すれば、今回のモデルでは1人あたり10秒以下で学習が完了することが期待できる。

## 特徴量抽出器のCNN分類モデルとしての性能

特徴量抽出器の学習(v1の事前学習)に用いた120クラス16576枚のデータを訓練8:評価2で分割し

* 学習所要時間: 200epoch学習するのにかかった時間
* 精度: 評価データに対する識別精度の最高値
* モデルサイズ: 学習結果としてに出力されるnpzファイルのサイズ

を比較した。また、評価データから10枚の画像をランダムに選び、1枚ずつ推論するのにかかった時間を計測し、平均値を推論所要時間とした。  
なお、学習にはGPU(Geforce GTX 1070)を、推論にはCPUを1Coreのみ使用(環境変数`OMP_NUM_THREADS=1`を設定)した。

| モデル | 学習所要時間(秒) | 精度(%) | モデルサイズ(MB) | 推論所要時間(秒/枚) |
| ------ | ---- | ---- | ---- | --- |
| V_12   | 3462 | 81.7 | 0.26 | 0.011 |
| V_16   | 3421 | 85.2 | 0.43 | 0.013 |
| V_20   | 3417 | 86.4 | 0.65 | 0.018 |
| V2_16  | 3880 | 89.2 | 4.2  | 0.027 |
| V2_20  | 3946 | 90.1 | 6.5  | 0.039 |
| A_16(v1) | 2761 | 56.3 | 0.66 | 0.007 |
| I2_24(v1) | 8102 | 58.1 | 1.2  | 0.011 |

v1のモデルと比較してv2のモデルは全体的に精度が向上した。GPUを使用した学習時は並列処理ができるためフィルタ数を増やしても所要時間に変化はないが、CPUを用いた推論はフィルタ数に応じて所要時間が延びる。行列が小さいためか、CPUを複数Core使用しても逆に速度が遅くなり、1Coreに制限した時が最速だった。  
Raspberry Pi上での推論速度はまだ計測していない。Raspberry Pi3上で `A_16(v1)` での推論速度が約0.2秒/枚であったことから、`V_16`なら0.4秒程度、`V2_16`でも1秒以内には推論できると期待される。

今回実装したモデルは、2つとも顔写真による人物分類以外のデータセットでも良い性能を示すことが[確認されている](https://github.com/nknytk/ml-study/blob/master/cnn/report.md)。
